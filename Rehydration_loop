# Script has been updated to iterate sequentially over all nodes listed in yba_config.yaml under node_list, preserving their order. Each node is processed one at a time in the order specified in the config.
#!/usr/bin/env python3
import subprocess
import logging
import time
import json
import yaml
from datetime import datetime

def load_config():
    """Load configuration from yba_config.yaml."""
    try:
        with open("yba_config.yaml", "r") as f:
            return yaml.safe_load(f)
    except Exception as e:
        raise RuntimeError(f"Failed to load configuration: {str(e)}")

def setup_logging():
    """Setup logging configuration."""
    log_file = f"rehydration_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler(), logging.FileHandler(log_file)]
    )
    return log_file

def run(cmd, capture_output=False):
    """Run a shell command and return its output."""
    logging.info(f"Running: {' '.join(cmd)}")
    result = subprocess.run(cmd, text=True, capture_output=capture_output, check=True)
    return result.stdout.strip() if capture_output else None

def resolve_instance_name_and_zone(ip, project):
    """Resolve instance name and zone from IP address."""
    result = run([
        "gcloud", "compute", "instances", "list",
        "--filter", f"networkInterfaces[0].networkIP={ip}",
        "--format", "json",
        "--project", project
    ], capture_output=True)
    data = json.loads(result)
    if not data:
        raise RuntimeError(f"No instance found for IP {ip}")
    return data[0]["name"], data[0]["zone"].split("/")[-1]

def stop_yugabyte_processes(yba_cli, yba_host, yba_token, universe_name, node_name):
    """Stop Yugabyte processes on the node."""
    try:
        run([
            yba_cli, "universe", "node", "stop",
            "-H", yba_host, "-a", yba_token,
            "--name", universe_name,
            "--node-name", node_name
        ])
        logging.info(f"✅ Stopped node {node_name} using YBA CLI")
    except subprocess.CalledProcessError as e:
        logging.warning(f"⚠️ Failed to stop node using YBA CLI: {e}")

def reprovision_and_start_node(yba_cli, yba_host, yba_token, universe_name, node_name):
    """Reprovision and start the node."""
    run([
        yba_cli, "universe", "node", "reprovision",
        "-H", yba_host, "-a", yba_token,
        "--name", universe_name,
        "--node-name", node_name
    ])
    time.sleep(10)
    run([
        yba_cli, "universe", "node", "start",
        "-H", yba_host, "-a", yba_token,
        "--name", universe_name,
        "--node-name", node_name
    ])

def get_boot_disk(instance_name, zone, project):
    """Get the boot disk name for an instance."""
    result = run([
        "gcloud", "compute", "instances", "describe", instance_name,
        "--zone", zone, "--project", project, "--format=json"
    ], capture_output=True)
    info = json.loads(result)
    for disk in info["disks"]:
        if disk.get("boot"):
            return disk["source"].split("/")[-1]
    raise RuntimeError("Boot disk not found")

def wait_for_status(instance_name, zone, project, expected, timeout=300):
    """Wait for instance to reach expected status."""
    for _ in range(timeout // 10):
        result = run([
            "gcloud", "compute", "instances", "describe", instance_name,
            "--zone", zone, "--project", project, "--format=json"
        ], capture_output=True)
        if json.loads(result).get("status") == expected:
            return
        time.sleep(10)
    raise TimeoutError(f"Timeout waiting for instance status: {expected}")

def stop_instance(instance_name, zone, project):
    """Stop the instance."""
    run(["gcloud", "compute", "instances", "stop", instance_name, "--zone", zone, "--project", project])
    wait_for_status(instance_name, zone, project, "TERMINATED")

def start_instance(instance_name, zone, project):
    """Start the instance."""
    run(["gcloud", "compute", "instances", "start", instance_name, "--zone", zone, "--project", project])
    wait_for_status(instance_name, zone, project, "RUNNING")

def replace_boot_disk(instance_name, zone, project, new_image, image_project, disk_size, disk_type):
    """Replace the boot disk with a new one."""
    old_disk = get_boot_disk(instance_name, zone, project)
    new_disk = f"{instance_name}-boot-{int(time.time())}"
    run([
        "gcloud", "compute", "disks", "create", new_disk,
        "--image", new_image, "--image-project", image_project,
        "--size", disk_size, "--type", disk_type,
        "--zone", zone, "--project", project
    ])
    run([
        "gcloud", "compute", "instances", "detach-disk", instance_name,
        "--disk", old_disk, "--zone", zone, "--project", project
    ])
    run([
        "gcloud", "compute", "instances", "attach-disk", instance_name,
        "--disk", new_disk, "--zone", zone, "--project", project,
        "--boot"
    ])

def get_data_disk_uuid(instance_name, zone, project, ssh_user):
    """Get the UUID of the data disk."""
    cmd = [
        "gcloud", "compute", "ssh", f"{ssh_user}@{instance_name}",
        "--zone", zone, "--project", project,
        "--internal-ip", "--command",
        "lsblk -o NAME,FSTYPE,UUID | grep xfs | grep -v sda"
    ]
    output = run(cmd, capture_output=True)
    device, _, uuid = output.strip().split()
    return f"/dev/{device}", uuid

def mount_data_disk(instance_name, zone, project, ssh_user, uuid):
    """Mount the data disk."""
    cmd = " && ".join([
        "sudo mkdir -p /data",
        f"sudo mount UUID={uuid} /data",
        "sudo chmod 777 /data",
        f"grep -q UUID={uuid} /etc/fstab || echo 'UUID={uuid} /data xfs defaults,nofail 0 2' | sudo tee -a /etc/fstab"
    ])
    run([
        "gcloud", "compute", "ssh", f"{ssh_user}@{instance_name}",
        "--zone", zone, "--project", project,
        "--internal-ip", "--command", cmd
    ])

def provision_node_agent(instance_name, zone, project, ssh_user):
    """Provision the node agent."""
    cmd = " && ".join([
        "echo '�� Reprovisioning yugabyte user and running node-agent-provision.sh...'",
        "sudo pkill -u yugabyte || true",
        "id yugabyte && sudo userdel -r yugabyte || true",
        "getent group yugabyte && (getent passwd | awk -F: '$4 == \"$(getent group yugabyte | cut -d: -f3)\"' | grep -q . || sudo groupdel yugabyte) || true",
        "sudo useradd -m -d /data/home/yugabyte -s /bin/bash yugabyte",
        "sudo mkdir -p /data/home/yugabyte",
        "sudo chown -R yugabyte:yugabyte /data/home/yugabyte",
        "sudo chmod 755 /data/home/yugabyte",
        "cd /data/2024.2.2.2-b2/scripts",
        "sudo ./node-agent-provision.sh"
    ])
    run([
        "gcloud", "compute", "ssh", f"{ssh_user}@{instance_name}",
        "--zone", zone, "--project", project,
        "--internal-ip", "--command", cmd
    ])

def verify_node_status(yba_cli, yba_host, yba_token, universe_name, node_name, instance_name, zone, project, ssh_user):
    """Verify that the node is in a good state after rehydration."""
    try:
        # Check if node is running in YBA
        result = run([
            yba_cli, "universe", "node", "status",
            "-H", yba_host, "-a", yba_token,
            "--name", universe_name,
            "--node-name", node_name
        ], capture_output=True)
        
        if "Running" not in result:
            raise RuntimeError(f"Node {node_name} is not in Running state")
            
        # Verify data disk is mounted
        cmd = [
            "gcloud", "compute", "ssh", f"{ssh_user}@{instance_name}",
            "--zone", zone, "--project", project,
            "--internal-ip", "--command",
            "mount | grep '/data'"
        ]
        result = run(cmd, capture_output=True)
        if not result:
            raise RuntimeError("Data disk is not mounted")
            
        return True
    except Exception as e:
        logging.error(f"Node verification failed: {str(e)}")
        return False

def process_node(config, node_info):
    """Process a single node in the rehydration workflow."""
    try:
        instance_ip = node_info['ip']
        yba_node_name = node_info['yba_node_name']
        gcp_instance_name = node_info['gcp_instance_name']
        
        # Resolve instance name and zone
        instance_name, zone = resolve_instance_name_and_zone(instance_ip, config["project_id"])
        
        logging.info(f"Processing node {yba_node_name} (GCP: {gcp_instance_name}) in zone {zone}")
        
        # Stop Yugabyte processes
        stop_yugabyte_processes(
            config["yba"]["yba_cli_path"],
            config["yba"]["yba_host"],
            config["yba"]["yba_api_token"],
            config["yba"]["universe_name"],
            yba_node_name
        )
        
        # Stop instance
        stop_instance(gcp_instance_name, zone, config["project_id"])
        
        # Replace boot disk
        replace_boot_disk(
            gcp_instance_name,
            zone,
            config["project_id"],
            config["new_image"],
            config["image_project"],
            f"{config['disk_size']}GB",
            config["disk_type"]
        )
        
        # Start instance
        start_instance(gcp_instance_name, zone, config["project_id"])
        
        # Wait for SSH
        time.sleep(config["ssh_wait_time"])
        
        # Mount data disk
        _, uuid = get_data_disk_uuid(gcp_instance_name, zone, config["project_id"], config["sh_user"])
        mount_data_disk(gcp_instance_name, zone, config["project_id"], config["sh_user"], uuid)
        
        # Provision node agent
        provision_node_agent(gcp_instance_name, zone, config["project_id"], config["sh_user"])
        
        # Reprovision and start node
        reprovision_and_start_node(
            config["yba"]["yba_cli_path"],
            config["yba"]["yba_host"],
            config["yba"]["yba_api_token"],
            config["yba"]["universe_name"],
            yba_node_name
        )
        
        # Verify node status
        if not verify_node_status(
            config["yba"]["yba_cli_path"],
            config["yba"]["yba_host"],
            config["yba"]["yba_api_token"],
            config["yba"]["universe_name"],
            yba_node_name,
            gcp_instance_name,
            zone,
            config["project_id"],
            config["sh_user"]
        ):
            raise RuntimeError("Node verification failed")
        
        logging.info(f"✅ Rehydration complete for node {yba_node_name}")
        return True, None
        
    except Exception as e:
        error_msg = str(e)
        logging.error(f"❌ Error processing node {yba_node_name}: {error_msg}")
        return False, error_msg

def generate_summary(start_time, success_count, failure_count, processed_nodes, config):
    """Generate a detailed summary of the rehydration process."""
    end_time = datetime.now()
    duration = end_time - start_time
    
    # Calculate hours, minutes, and seconds
    hours, remainder = divmod(duration.total_seconds(), 3600)
    minutes, seconds = divmod(remainder, 60)
    
    summary = f"""
{'='*80}
REHYDRATION PROCESS SUMMARY
{'='*80}

Process Duration: {int(hours)}h {int(minutes)}m {int(seconds)}s
Start Time: {start_time.strftime('%Y-%m-%d %H:%M:%S')}
End Time: {end_time.strftime('%Y-%m-%d %H:%M:%S')}

Total Nodes Processed: {len(processed_nodes)}
Successful Nodes: {success_count}
Failed Nodes: {failure_count}
Success Rate: {(success_count/len(processed_nodes))*100:.1f}%

{'='*80}
NODE DETAILS
{'='*80}
"""
    
    # Add details for each node
    for node in processed_nodes:
        status = "✅ SUCCESS" if node['success'] else "❌ FAILED"
        summary += f"""
Node: {node['name']}
GCP Instance: {node['gcp_name']}
IP: {node['ip']}
Zone: {node['zone']}
Status: {status}
"""
        if not node['success'] and node.get('error'):
            summary += f"Error: {node['error']}\n"
        summary += "-"*80 + "\n"
    
    # Add configuration summary
    summary += f"""
{'='*80}
CONFIGURATION SUMMARY
{'='*80}
Project: {config['project_id']}
Zone: {config['zone']}
Image: {config['new_image']}
Disk Type: {config['disk_type']}
Disk Size: {config['disk_size']}GB
SSH User: {config['sh_user']}
YBA Host: {config['yba']['yba_host']}
Universe: {config['yba']['universe_name']}

{'='*80}
"""
    
    return summary

def main():
    """Main function to process all nodes."""
    # Setup logging
    log_file = setup_logging()
    
    # Load configuration
    config = load_config()
    
    start_time = datetime.now()
    success_count = 0
    failure_count = 0
    processed_nodes = []
    
    logging.info(f"Starting rehydration process for {len(config['yba']['node_list'])} nodes")
    
    for node_info in config["yba"]["node_list"]:
        yba_node_name = node_info['yba_node_name']
        gcp_instance_name = node_info['gcp_instance_name']
        
        logging.info(f"Processing node {yba_node_name} (GCP: {gcp_instance_name})")
        
        success, error = process_node(config, node_info)
        
        if success:
            success_count += 1
            processed_nodes.append({
                'name': yba_node_name,
                'gcp_name': gcp_instance_name,
                'ip': node_info['ip'],
                'zone': config['zone'],
                'success': True
            })
        else:
            failure_count += 1
            processed_nodes.append({
                'name': yba_node_name,
                'gcp_name': gcp_instance_name,
                'ip': node_info['ip'],
                'zone': config['zone'],
                'success': False,
                'error': error
            })
        
        # Add a delay between nodes
        if config["yba"]["node_list"].index(node_info) < len(config["yba"]["node_list"]) - 1:
            logging.info("Waiting 60 seconds before processing next node...")
            time.sleep(60)
    
    # Generate and log the summary
    summary = generate_summary(start_time, success_count, failure_count, processed_nodes, config)
    logging.info(summary)
    
    # Save summary to a separate file
    summary_file = f"rehydration_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(summary_file, 'w') as f:
        f.write(summary)
    
    logging.info(f"Summary saved to {summary_file}")
    
    if failure_count > 0:
        logging.warning("Some nodes failed to process. Check the logs for details.")
        return 1
    return 0

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
